#!/usr/bin/env bash

################################################################################
################### Load Helpers & Global BenchBot Settings ####################
################################################################################

set -euo pipefail
IFS=$'\n\t'
abs_path=$(readlink -f $0)
pushd $(dirname $abs_path) > /dev/null
source .helpers
popd > /dev/null

################################################################################
########################### Script Specific Settings ###########################
################################################################################

DEFAULT_PREFIX="batch"

################################################################################
######################## Helper functions for commands #########################
################################################################################

usage_text="$(basename "$0") -- Helper script for running a solution against multiple
environments in a single command. Use this script when you have developed a
task solution that you would like to extensively test, or when you would like
create a submission to a challenge. Addons can include 'batches' which are
environment lists, like those used for evaluating tasks in official challenges.

The $(basename "$0") script is roughly equivalent to the following:

    for ENV,I in ENV_LIST:
      benchbot_run -t TASK -e ENV -f 
      benchbot_submit -r PREFIX_I.json SUBMISSION_COMMAND

    if [-z|--zip]:
      zip PREFIX.zip PREFIX_[0-9]*.json

    if [-s|--score-results]:
      benchbot_eval -o PREFIX_scores.json PREFIX_[0-9]*.json

As such, see the help documentation for 'benchbot_run', 'benchbot_submit', &
'benchbot_eval' for further details about how each of the below arguments work.

USAGE:

    Get information about the submission options:
        $(basename "$0") [-h|--help]

    Run a submission natively for the task semantic_slam:passive:ground_truth
    in each of the available house scenes, saving the results with the default
    prefix '$DEFAULT_PREFIX':
        $(basename "$0") [-t|--task] semantic_slam:passive:ground_truth \\
          [-e|--envs] house:1,house:2,house:3,house:4,house:5 \\
          [-n|--native] COMMAND_TO_RUN

    Run a submission for the scd:active:dead_reckoning task in a containerised
    environment, for a list of scenes specified in the environment batch called
    'challenge_1', saving the results with the prefix 'mix'. Then evaluate the
    results to produce a final score:
        $(basename "$0") [-t|--task] scd:active:dead_reckoning \\
          [-E|--envs-batch] challenge_1 [-p|--prefix] mix [-s|--score-results] \\
          [-c|--containerised] DIRECTORY_FOR_SUBMISSION

        ... (contents of 'challenge_1' batch) ...
        name: challenge:1
        environments:
          - miniroom:1:2
          - house:2:3
          - apartment:3:4
          - office:4:5
          - company:5:1

OPTION DETAILS:

    -h, --help             
            Show this help menu.

    -c, --containerised
            Uses the Dockerfile in the specified directory to start a Docker
            container running your solution for each environment. This requires
            an extra parameter specifying the dierctory of the Dockerfile for
            your solution. See '-c, --containerised' in 'benchbot_submit
            --help' for further details on containerised BenchBot submissions.

    -e, --envs
            A comma-separated list of environments for $(basename "$0") to
            iterate over (e.g. \"house:1,miniroom:2,office:3\"). See the
            '-e, --env' arg in 'benchbot_run --help' for further details of
            specifying valid environments, & 'benchbot_run --list-envs' for a
            complete list of supported environments.

    -E, --envs-batch
            The name of an environment batch specifying a list of environments.
            The $(basename "$0") script will iterate over each specified
            environment. See '-e, --envs' above for further details on valid
            environment specifications.

    --list-batches
            Lists all supported environment batches. These can be used with the
            '--required-envs-batch' option. Use '--show-batch' to see more
            details about a batch.

    -n, --native
            Runs everything after this flag as a command directly on your
            system for each environment. See '-n, --native' in 'benchbot_submit
            --help' for further details on native BenchBot submissions.

    -p, --prefix
            Prefix to use in naming of files produced by $(basename "$0"). If
            this option is not included, the default value '$DEFAULT_PREFIX' will
            be used. For example, a batch of 5 environments with the [-z|--zip]
            argument & prefix 'semslam' will produce the following files:
                semslam_1.json
                semslam_2.json
                semslam_3.json
                semslam_4.json
                semslam_5.json
                semslam.zip
                semslam_scores.json

    -r, --robot
            Configure BenchBot to use a specifc robot. Every environment in the
            requested batch will be run with this robot (so make sure they
            support the robot). See '-r, --robot' in 'benchbot_run --help' for
            further details on specifying valid robots, & 'benchbot_run
            --list-robots' for a complete list of supported robots.

    -s, --score-results
            Perform evaluation on the batch of results produced by $(basename "$0").
            The scores from each results file in the batch are then combined
            into a final set of scores for your algorithm, on the tested task.
            Scores are combined using the approach described in 'benchbot_eval
            --help'.

    --show-batch
            Prints information about the provided batch name if installed. The
            corresponding file's location will be displayed, with a snippet of
            its contents.

    -t, --task             
            Configure BenchBot for a specific task style. Every environment in
            the requested batch will be run with this task. See '-t, --task' in
            'benchbot_run --help' for further details on specifying valid tasks, 
            & 'benchbot_run --list-tasks' for a complete list of supported
            tasks.

    -v, --version
            Print version info for current installation.

    -z, --zip
            Produce a ZIP file of the results once all environments in the
            batch have been run. The ZIP file will be named using the value
            provided by the '-p, --prefix' argument (i.e. 'PREFIX.zip'), with
            the default prefix '$DEFAULT_PREFIX' used if none is provided.

FURTHER DETAILS:

    See the README of this repository for further details. For further details
    on each of the individual components ('benchbot_run', 'benchbot_submit',
    'benchbot_eval'), see their individual help documentation & READMEs.
    
    Please contact the authors of BenchBot for support or to report bugs:
        b.talbot@qut.edu.au
    "

collision_warn="WARNING: Running of environment '%s' in passive mode resulted in a
collision. This should not happen, so this environment will be rerun!"

run_err="ERROR: Running of environment '%s' failed with the error printed above.
Quitting batch execution."

submission_err="ERROR: Submission for environment '%s' failed with the error printed
above. Quitting batch execution."

_list_batches_pre=\
"The following environment batches are available in your installation:
    "

run_pid=
function kill_run() {
  if [ ! -z $run_pid ]; then
    kill -TERM $run_pid &> /dev/null
    wait $run_pid
    run_pid=
  fi
}

submit_pid=
function kill_submit() {
  if [ ! -z $submit_pid ]; then
    kill -TERM $submit_pid &> /dev/null
    wait $submit_pid
    submit_pid=
  fi
}

function exit_gracefully() {
  kill_run
  kill_submit
  echo ""
  exit ${1:-0}
}

function validate_envs() {
  # $1 requested envs, $2 requested envs batch
  if [ ! -z "$1" ] && [ ! -z "$2" ]; then
    printf "${colour_red}%s${colour_nc}\n" \
      "ERROR: Only '--envs' or '--envs-batch' is valid, not both."
  elif [ -z "$1" ] && [ -z "$2" ]; then
    printf "${colour_red}%s %s${colour_nc}\n" \
      "ERROR: No environments were provided via either" \
      "'--envs' or '--envs-batch'"
  fi
}

################################################################################
#################### Parse & handle command line arguments #####################
################################################################################

# Safely parse options input
_args='envs:,envs-batch:,containerised,help,list-batches,native,prefix:,\
robot:,score-results,show-batch,task:,version,zip '
parse_out=$(getopt -o e:E:chnp:r:st:vz --long "$_args" -n "$(basename "$0")" \
  -- "$@")
if [ $? != 0 ]; then exit 1; fi
containerised=
eval set -- "$parse_out"
evaluate=
envs_str=
envs_batch=
native=
prefix="$DEFAULT_PREFIX"
robot=
submit_args=
task=
zip=
while true; do
  case "$1" in
    -c|--containerised)
      containerised='--containerised' ; shift ;;
    -e|--envs)
      envs_str="$2" ; shift 2 ;;
    -E|--envs-batch)
      envs_batch="$2" ; shift 2 ;;
    -h|--help)
      echo "$usage_text" ; shift ; exit 0 ;;
    --list-batches)
      list_content "batches" "$_list_batches_pre" "a" 2; exit $? ;;
    -n|--native)
      native='--native' ; shift ;;
    -p|--prefix)
      prefix="$2"; shift 2 ;;
    -r|--robot)
      robot="$2"; shift 2 ;;
    -s|--score-results)
      evaluate=true; shift ;;
    --show-batch)
      show_content "batches" "$2" 2; exit $? ;;
    -t|--task)
      task="$2"; shift 2 ;;
    -v|--version)
      print_version_info; exit ;;
    -z|--zip)
      zip=true; shift ;;
    --)
      shift ; submit_args="$@"; break ;;
    *)
      echo "$(basename "$0"): option '$1' is unknown"; shift ; exit 1 ;;
  esac
done

# Process envs & envs-file here (defer all other argument evaluation to the
# appropriate scripts which use the values)
err="$(validate_envs "$envs_str" "$envs_batch")"
if [ ! -z "$err" ]; then echo "$err"; exit 1; fi
if [ ! -z "$envs_str" ]; then
  envs_list=($(echo "$envs_str" | tr ',' '\n'))
elif [ ! -z "$envs_batch" ]; then
  envs_list=($(run_manager_cmd 'print("\n".join(get_value_by_name(\
    "batches", "'$envs_batch'", "environments")))'))
fi

################################################################################
####################### Print settings prior to running ########################
################################################################################

trap exit_gracefully SIGINT SIGQUIT SIGKILL SIGTERM

header_block "Dumping settings before running batch" $colour_magenta

_ind="$(printf "%0.s " {1..8})"
printf "\nUsing the following static settings for each environment:\n"
printf "$_ind%-25s%s\n" "Selected task:" "${task:-None}"
printf "$_ind%-25s%s\n$_ind" "Selected robot:" "${robot:-None}"
if [ ! -z "$containerised" ]; then
  printf "%-25s%s\n" "Dockerfile to build:" \
    "$(echo "$submit_args" | awk '{print $2}')/Dockerfile"
elif [ ! -z "$native" ]; then
  printf "%-25s%s\n" "Command to execute:" "$(echo "${submit_args[@]}")"
else
  printf "%-25s%s\n" "Command to execute:" "None"
fi

printf "\nIterating through the following environment list:\n$_ind"
if [ -z "$envs_list" ]; then
  printf "None\n"
else
  echo "${envs_list[@]}" | sed "s/ /\n$_ind/g" 
fi

printf "\nPerforming the following after all environments have been run:\n"
printf "$_ind%-25s%s\n" "Create results *.zip:" \
  "$([ -z "$zip" ] && echo "No" || echo "Yes")"
printf "$_ind%-25s%s\n\n" "Evalute results batch:" \
  "$([ -z "$evaluate" ] && echo "No" || echo "Yes")"

################################################################################
############### Iterate over each of the requested environments ################
################################################################################

if [ -z "$envs_list" ]; then
  echo "No environments provided; exiting."
  exit 0
fi

results_list=()
i=0
while [ $i -lt ${#envs_list[@]} ]; do
  # Run the submission in the environment, waiting until something finishes
  header_block "Gathering results for environment: ${envs_list[$i]}" \
    $colour_magenta
  benchbot_run -t "${task:-None}" -e "${envs_list[$i]}" -f &> /tmp/benchbot_run_out &
  run_pid=$!
  benchbot_submit -r "${prefix}_$i.json" $containerised $native $submit_args &
  submit_pid=$!
  while ps -p $run_pid &>/dev/null && ps -p $submit_pid &>/dev/null; do
    sleep 1
  done
  sleep 5

  # Run should never die normally, so treat this as an error
  if ! $(ps -p $run_pid &>/dev/null); then
    echo ""
    kill_submit
    header_block "Crash detected for environment: ${envs_list[$i]}" \
      ${colour_magenta}
    printf "\n${colour_magenta}%s${colour_nc}\n" \
      "Dumping output of 'benchbot_run' below:"
    cat /tmp/benchbot_run_out
    printf "\n${colour_red}$run_err${colour_nc}\n" "${envs_list[$i]}"
    exit 1
  fi

  # Handle the result of failed submissions (looking for an error code)
  wait $submit_pid
  submit_result=$?
  if [ $submit_result -ne 0 ]; then
    echo ""
    kill_run
    printf "\n${colour_red}$submission_err${colour_nc}\n" "${envs_list[$i]}"
    exit 1
  fi

  # Move to next environment (excluding case of collisions whilst in passive
  # mode)
  if [ ! -z "$(echo "$task" | grep -v "passive")" ] || \
      [ -z "$(docker run --rm --network $DOCKER_NETWORK -it \
        "$DOCKER_TAG_BACKEND" /bin/bash -c \
        'curl '$HOSTNAME_SUPERVISOR':'$PORT_SUPERVISOR'/simulator/is_collided' \
        | grep "true")" ]; then
    results_list+=("${prefix}_$i.json")
    ((i++))
  else
    printf "\n${colour_yellow}$collision_warn${colour_nc}\n\n" \
      "${envs_list[$i]}"
  fi
  kill_run
done

################################################################################
############################ Processing of results #############################
################################################################################

header_block "Processing results from batch" $colour_magenta

if [ ! -z "$zip" ]; then
  echo -e "${colour_magenta}Zipping up results ... ${colour_nc}\n"
  rm -vf "${prefix}.zip" && zip "${prefix}.zip" "${results_list[@]}"
  echo ""
fi

if [ ! -z "$evaluate" ]; then
  echo -e "${colour_magenta}Evaluating results... ${colour_nc}"
  benchbot_eval -o "${prefix}_scores.json" --required-task "$task" \
    --required-envs $(echo "${envs_list[@]}" | tr ' ' ',') \
    $([ -z "$zip" ] && echo "${results_list[@]}" || echo "${prefix}.zip")
else
  echo "Done."
fi

