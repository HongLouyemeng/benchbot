#!/usr/bin/env bash

################################################################################
################### Load Helpers & Global BenchBot Settings ####################
################################################################################

abs_path=$(readlink -f $0)
pushd $(dirname $abs_path) > /dev/null
source .helpers
popd > /dev/null

################################################################################
########################### Script Specific Settings ###########################
################################################################################

SUBMISSION_CONTAINER_NAME="submission"

################################################################################
######################## Helper functions for commands #########################
################################################################################

usage_text="$(basename "$0") -- Submission script for running your solution to the Scene
Understanding Challenge against a running simulator. It supports 3 different
modes of submission:

    1. native: 
       Run your code in your host system without any containerisation (useful
       for when you are developing and testing things). This assumes that the
       simulator is already running.

    2. containerised: 
       Bundles up your code & executes it using Docker & the Dockerfile
       provided with your code (useful for testing a competition submission
       locally before submitting). The created Docker image talks to a running
       simulator.

    3. submission: 
       Bundles up your code and saves a *.tgz ready for submission to the Scene
       Understanding Challenge.

USAGE:

    Get information about the submission options:
        $(basename "$0") [-h|--help]

    Submit & run natively on your system:
        $(basename "$0") [-n|--native] COMMAND_TO_RUN

    Submit, compile into a containerised environment, & run the container on
    your machine:
        $(basename "$0") [-c|--containerised] DIRECTORY_FOR_SUBMISSION
        
    Bundle up your solution into a *.tgz ready for submssion to the challenge:
        $(basename "$0") [-s|--submission] DIRECTORY_FOR_SUBMISSION

OPTION DETAILS:

    -h,--help             
            Show this help menu.

    -n, --native
            Runs your solution directly on your system without applying any 
            containerisation (useful when you are developing & testing your 
            solution). Everything after this flag is treated as the command used
            to run your solution (required). For example, if your solution is a
            Python script called 'solution.py':

                    $(basename "$0") -n python solution.py

    -c, --containerised
            Uses the Dockerfile provided with your solution to start a Docker
            container running your solution. Dockerfiles are the means in which
            you concisely communicate WHAT system configuration is needed to
            run your solution (i.e. do you need Python3, cuda, ROS, etc). This
            mode requires an extra parameter specifying the directory where
            your solution resides. For example, if your solution is in the 
            current directory:

                    $(basename "$0") -c .

    -s, --submission
            Bundles up your solution into a *.tgz ready for submission. The 
            directory where your solution exists is a required extra parameter.
            Optionally, another parameter can be provided to specify a name
            (and / or what directory) to put the *.tgz. For example, to bundle
            up your soluition in the current directory on your desktop:

                    $(basename "$0") -s . \$HOME/Desktop

    -e, --evaluate-results
            Evaluate the results produced by the provided submission after it
            has finished running. This will assume that your submission saves
            results to the location referenced by 'benchbot_api.RESULT_LOCATION'
            (currently '/tmp/benchbot_result'). Hence, evaluation will not work
            as expected if the submission saves results in any other location.

    -r, --results-location
            Copy results produced by the submission to another location. Note:
            this does not change where '-e' looks for results, it merely
            specifies another location where the user can view the results of
            their submission. Like '-e', this flag will not work as expected if
            the submission does not save results in the expected location
            ('benchbot_api.RESULT_LOCATION').

FURTHER DETAILS:

    See the 'benchbot_examples' repository for example solutions to test with
    the submission system & simulator to get started.
    
    Please contact the authors of BenchBot for support or to report bugs:
        b.talbot@qut.edu.au
    "

SELECTED_MODE=
SELECTED_OPTIONS=

function opt_select_mode() {
  if [ ! -z $SELECTED_MODE ]; then
    return 0
  fi
  case "$1" in
    -n|--native)
      SELECTED_MODE="native" ;;
    -c|--containerised)
      SELECTED_MODE="containerised" ;;
    -s|--submission)
      SELECTED_MODE="submission" ;;
    *)
      echo "$(basename "$0"): '$1' mode is unsupported" ; exit 1 ;;
  esac
  shift
  SELECTED_OPTIONS=( $(echo "$@" | sed 's/ --//') )
}

function remove_submission_container() {
  # Cleanup containers if we ran in containerised mode
  if [ "$SELECTED_MODE" == "containerised" ]; then
    printf "\n"
    header_block "Cleaning up user containers" ${colour_blue}
    docker system prune -f  # TODO this is probably too brutal
  fi
}

################################################################################
#################### Parse & handle command line arguments #####################
################################################################################

# Safely parse options input
parse_out=$(getopt -o ehc:n:r:s:v --long \
  evaluate-results,help,containerised:,native:,results-location:,submission:,version \
  -n "$(basename "$0")" -- "$@")
if [ $? != 0 ]; then exit 1; fi
eval set -- "$parse_out"
results_location=
evaluate=
while true; do
  case "$1" in
    -e|--evaluate-results)
      evaluate=true ; shift ;;
    -h|--help)
      echo "$usage_text" ; shift ; exit 0 ;;
    -n|--native|-c|--containerised|-s|--submission)
      opt_select_mode "$@"; break ;;
    -r|--results_location)
      results_location="$2"; shift 2 ;;
    -v|--version)
      print_version_info; exit ;;
    --)
      shift ; break ;;
    *)
      echo "$(basename "$0"): option '$1' is unknown"; shift ; exit 1 ;;
  esac
done
if [ -z $SELECTED_MODE ]; then
  echo "$usage_text"; exit 0
fi

# Bail if we have received mode options we can't do anything with
# TODO handle passing evaluate and / or results when running in submission mode
case "$SELECTED_MODE" in
  containerised|submission)
    if [ ! -d "${SELECTED_OPTIONS[0]}" ]; then
      s="$(basename "$0"): directory '${SELECTED_OPTIONS[0]}' provided with "
      s+="mode\n'$SELECTED_MODE' does not exist. Exiting..."
      echo -e "$s"
      exit 1
    fi ;;&
  submission)
    if [ -z "$evaluate" ] || [ -z "$results_location" ]; then
      s="$(basename "$0"): cannot create results or perform evaluation from " 
      s+="\nsubmission mode as no code is run. Please run again in a different "
      s+="\nmode."
      echo -e "$s"
      exit 1
    fi
    ;;
esac

# We are going to submit; pull all useful data from selected settings out
# before beginning
selected_command=
selected_code_dir=
selected_out_location=
case "$SELECTED_MODE" in
  native)
    selected_command="${SELECTED_OPTIONS[@]}" ;;
  containerised|submission)
    selected_code_dir="${SELECTED_OPTIONS[0]}" ;;&
  submission)
    if [ ${#SELECTED_OPTIONS[@]} -gt 1 ]; then
      selected_out_location="${SELECTED_OPTIONS[1]}"
    fi
    abs_path=$(realpath "$selected_code_dir")
    if [ -z "$selected_out_location" ]; then
      selected_out_location="$abs_path"
    fi
    if [ -d "$selected_out_location" ]; then
      selected_out_location="$selected_out_location/$(basename "$abs_path")"
    fi
    if [[ ! "$selected_out_location" =~ "." ]]; then
      selected_out_location+=".tgz"
    fi ;;
esac


################################################################################
################## Submit your BenchBot solution as requested ##################
################################################################################

trap remove_submission_container EXIT

# Print some configuration information
echo "Submitting to the BenchBot system with the following settings:

    Submission mode:             $SELECTED_MODE"
if [ -n "$selected_command" ]; then
  echo \
"    Command to execute:          $selected_command"
fi
if [ -n "$selected_code_dir" ]; then
  echo \
"    Directory of solution:       $selected_code_dir"
fi
if [ -n "$selected_out_location" ]; then
  echo \
"    Bundling output filename:    $selected_out_location"
fi
echo \
"    Perform evaluation:          "\
"$([ -z "$evaluate" ] && echo "No" || echo "Yes")"
if [ -n "$results_location" ]; then
  echo \
"    Results save location:       $results_location"
fi
echo ""

# Actually perform the submission
header_block "Running submission in '$SELECTED_MODE' mode" ${colour_green}

# Clear out any previous results in default location
if [ ! -z "$results_location" ] || [ ! -z "$evaluate" ]; then
  results_src=$(python -c \
    'from benchbot_api.benchbot import RESULT_LOCATION; print(RESULT_LOCATION)')
  rm -rf "$results_src"
  printf "\nRemoved any existing cached results from: $results_src\n\n"
fi

# Handle the submission
if [ "$SELECTED_MODE" == "native" ]; then
  # This is native submission mode
  echo -e \
    "Running submission natively via command:\n\t'$selected_command' ...\n"
  eval "$selected_command"
  result=$?
elif [ "$SELECTED_MODE" == "submission" ]; then
  # This is bundling up submission mode
  echo -e "Bundling up submission from '$selected_code_dir' ...\n"
  pushd "$selected_code_dir" >/dev/null
  tar -czvf "$selected_out_location" *
  result=$?
  popd >/dev/null
  echo -e "\nSaved to: $selected_out_location"
else
  # This is a containerised submission
  echo "Running submission from '$selected_code_dir' with containerisation ..."
  pushd "$selected_code_dir" >/dev/null
  submission_tag="benchbot/submission:"$(echo "$(pwd)" | sha256sum | cut -c1-10)
  docker build -t "$submission_tag" .
  result=$?
  if [ $result -ne 0 ]; then
    echo "Docker build returned a non-zero error code: $build_ret"
  else
    xhost +local:root
    docker run --gpus all -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
            --network "$DOCKER_NETWORK" --name="$SUBMISSION_CONTAINER_NAME" \
            --hostname="$name" -i -t "$submission_tag" 
    result=$?
    xhost -local:root
  fi
  popd >/dev/null
fi

# Exit here if the submission failed
if [ $result -ne 0 ]; then
  printf "${colour_red}\n%s: %d${colour_nc}\n" \
    "Submission failed with result error code" "$result"
  exit $result
fi

# Perform any evaluation that may have been requested by the caller
if [ ! -z "$results_location" ] || [ ! -z "$evaluate" ]; then
  header_block "Processing results" ${colour_blue}

  # Pull the results out of the container if appropriate
  if [ "$SELECTED_MODE" == "containerised" ]; then
    if ! docker cp "${SUBMISSION_CONTAINER_NAME}:${results_src}"\
      "${results_src}" 2>/dev/null; then
      printf "${colour_red}\n%s%s${colour_nc}\n" \
        "Failed to extract results from submission container; were there any?"
      exit 1
    fi
    printf "\nExtracted results from container '%s', to '%s'.\n" \
      "$SUBMISSION_CONTAINER_NAME" "$results_src"
  fi

  # Bail if there are no results available
  if [ ! -f "$results_src" ]; then
    printf "\n${colour_red}%s\n  ${results_src}${colour_nc}\n" \
      "Requested use of results, but the submission saved no results to: "
    exit 1
  fi

  # Copy results to a new location if requested
  if [ ! -z "$results_location" ]; then
    printf "\nCopying results from '%s' to '%s' ...\n" "$results_src" \
      "$results_location"
    rsync -avP "$results_src" "$results_location"
  fi

  # Run evaluation on the results if requested
  if [ ! -z "$evaluate" ]; then
    if [ -z "$results_location" ]; then results_location="$results_src"; fi
    printf "\nRunning evaluation on results from '%s' ... \n" \
      "$results_location"
    benchbot_eval "$results_location"
  fi
fi

exit 0
