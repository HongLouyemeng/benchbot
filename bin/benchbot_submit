#!/usr/bin/env bash

################################################################################
################### Load Helpers & Global BenchBot Settings ####################
################################################################################

set -euo pipefail
IFS=$'\n\t'
abs_path=$(readlink -f $0)
pushd $(dirname $abs_path) > /dev/null
source .helpers
popd > /dev/null

################################################################################
########################### Script Specific Settings ###########################
################################################################################

SUBMISSION_CONTAINER_NAME="benchbot_submission"
SUBMISSION_OUTPUT_DEFAULT="../submission.tgz"

################################################################################
######################## Helper functions for commands #########################
################################################################################

usage_text="$(basename "$0") -- Submission script for running your solution to the Scene
Understanding Challenge against a running simulator. It supports 5 different
modes of submission:

    1. native: 
       Run your code in your host system without any containerisation (useful
       for when you are developing and testing things). This assumes that the
       simulator is already running.

    2. containerised: 
       Bundles up your code & executes it using Docker & the Dockerfile
       provided with your code (useful for testing a competition submission
       locally before submitting). The created Docker image talks to a running
       simulator.

    3. submission: 
       Bundles up your code and saves a *.tgz ready for submission to a
       challenge (not currently in use due to code being run locally on your
       machine)

    4. native (example):
       Same as native, but uses an example provided in a BenchBot add-on. The
       example already defines the native command to run, you just have to add
       an runtime args via the --args flag if necessary.

    5. containerised (example):
       Same as containerised, but uses an example provided in a BenchBot
       add-on. The example already defines where the Dockerfile exists, you
       just have to add runtime args via the --args flag if necessary.

USAGE:

    Get information about the submission options:
        $(basename "$0") [-h|--help]

    Submit & run natively on your system:
        $(basename "$0") [-n|--native] COMMAND_TO_RUN

    Submit, compile into a containerised environment, & run the container on
    your machine:
        $(basename "$0") [-c|--containerised] DIRECTORY_CONTAINING_DOCKERFILE
        
    Bundle up your solution into a *.tgz ready for submssion to the challenge:
        $(basename "$0") [-s|--submission] DIRECTORY_FOR_SUBMISSION

    Submit, compile into a containerised environment, run the container on your
    machine, & evaluate the results which are also saved to 'my_results.json':
        $(basename "$0") [-e|--evaluate-with] \\
          [-r|--results-location] 'my_results.json' \\
          [-c|--containerised] DIRECTORY_FOR_SUBMISSION

    Run an example, with some runtime arguments:

        $(basename "$0") --example EXAMPLE_NAME -n \\
          -a '--arg1 value --arg2 value'

 
OPTION DETAILS:

    -h,--help             
            Show this help menu.

    -a, --args
            Runtime arguments to pass through to the submission. You will need
            to use quotes to properly handle multiple arguments. For example:

              $(basename "$0") -n python3 my_script.py -a '--arg1 a --arg2 b'

            These arguments are handled differently depending on the mode:
              - native: they are appended to the end of the command
              - containerised: they are appended to the end of the Dockerfile's
                'CMD'
              - submission: a single positional argument is used to specify the
                *.tgz's save location

    -c, --containerised
            Uses the Dockerfile provided with your solution to start a Docker
            container running your solution. Dockerfiles are the means in which
            you concisely communicate WHAT system configuration is needed to
            run your solution (i.e. do you need Python3, cuda, ROS, etc). 

            This mode requires an extra parameter specifying either:
              - the directory where your solution's Dockerfile resides (the
                filename is assumed to be 'Dockerfile'), or
              - the full path for your solution's Dockerfile (supports custom
                filenames)

            For example, the following commands are equivalent for a solution
            with a Dockerfile named 'Dockerfile' in the current directory: 

                    $(basename "$0") -c .
                    $(basename "$0") -c ./Dockerfile

    -E, --example
            Name of an installed example to run. All examples at least support
            native operation, with most also supporting containerised
            operation.

            Examples run in native mode by default. Examples can still be run
            in containerised mode, but require the '--example-containerised'
            flag. 

            (use '--list-examples' to see a list of installed example)

    --example-containerised
            Runs the example in containerised mode instead of native mode. This
            option is only valid when running an example.

    -e, --evaluate-with
            Name of the evaluation method to use for evaluation of the provided
            submission after it has finished running. Evaluation will only be
            performed if this option is provided. 
            
            This option assumes your submission saves results to the location
            referenced by 'benchbot_api.RESULT_LOCATION' (currently
            '/tmp/benchbot_result'). Evaluation will not work as expected
            results are not saved to that location.

            See '--list-methods' in 'benchbot_eval' for a list of supported
            methods, and 'benchbot_eval --help' for a description of the
            scoring process.

    --list-examples
            List all available examples. The listed examples are printed in the
            format needed for the '--example' option. Use '--show-example' to
            see more details about an example.

    -n, --native
            Runs your solution directly on your system without applying any 
            containerisation (useful when you are developing & testing your 
            solution). 

            This mode requires an extra parameter specifying the command to
            natively run your solution. For example, if your solution is a
            Python script called 'solution.py':

                    $(basename "$0") -n 'python3 solution.py'

    -r, --results-location
            Copy results produced by the submission to another location. Note:
            this does not change where '-e' looks for results, it merely
            specifies another location where the user can view the results of
            their submission. Like '-e', this flag will not work as expected if
            the submission does not save results in the expected location
            ('benchbot_api.RESULT_LOCATION').

    -s, --submission
            Bundles up your solution into a *.tgz ready for submission. The 
            directory where your solution exists is a required extra parameter.

            Optionally, you can also provide a positional arg via the '-a' flag
            to specify where to put the *.tgz. For example, to bundle up your
            solution in the current directory on your desktop:

                    $(basename "$0") -s . -a \$HOME/Desktop

    --show-example
            Prints information about the provided example if installed. The
            corresponding YAML's location will be displayed, with a snippet of
            its contents.

    -v,--version
            Print version info for current installation.

FURTHER DETAILS:

    Please contact the authors of BenchBot for support or to report bugs:
        b.talbot@qut.edu.au
    "

mode_duplicate_err="ERROR: Multiple submission modes were selected. Please ensure only 
one of -n|-c|-s is provided."

mode_selection_err="ERROR: No valid submission mode was selected (-n|-c|-s). Please see 
'benchbot_submit --help' for further details."

_list_examples_pre=\
"The following BenchBot examples are available in your installation:
    "

function expand_mode() {
  if [ -z "${1:-}" ]; then return; fi
  mode="${1//-}"
  if [[ "$mode" == n* ]]; then 
    echo "native";
  elif [[ "$mode" == c* ]]; then
    echo "containerised";
  elif [[ "$mode" == s* ]]; then
    echo "submission";
  fi
}

active_pid=
exit_code=
function exit_gracefully() {
  # $1 mode (numeric)
  echo ""

  # Pass the signal to the currently running process
  if [ -n "$active_pid" ]; then
    kill -TERM $active_pid &> /dev/null || true
    wait $active_pid || true
    active_pid=
  fi
  
  # Cleanup containers if we ran in containerised mode
  if [ "$1" == 1 ] || [ "$1" == 4 ]; then
    printf "\n"
    header_block "Cleaning up user containers" ${colour_blue}
    docker system prune -f  # TODO this is probably too brutal
  fi

  exit ${exit_code:-0}
}

function submission_command() {
  # $1 mode (numeric), $2 mode_details, $3 example name, $4 args
  if [ "$1" == 0 ]; then
    echo "$2 ${4:-}";
  elif [ $1 == 1 ]; then
    echo "docker build -f $(submission_dockerfile "$1" "$2" "$3") ."
  elif [ $1 == 2 ]; then
    echo "tar -czvf $([ -z "${4:-}" ] && \
      echo "$SUBMISSION_OUTPUT_DEFAULT" || echo "$args") ."
  elif [ $1 == 3 ]; then
    echo "$(run_manager_cmd 'print(get_value_by_name("examples", "'$3'", \
      "native_command"))') ${4:-}"
  elif [ $1 == 4 ]; then
    contdir="$(run_manager_cmd 'x = get_value_by_name("examples", "'$3'", \
      "container_directory"); x and print(x)')"
    echo "docker build -f $(submission_dockerfile "$1" "$2" "$3") $( \
      [ -n "$contdir" ] && echo "$contdir" || echo ".")"
  fi
}

function submission_directory() {
  # $1 mode (numeric), $2 mode_details, $3 example name
  if [ "$1" == 0 ] || [ "$1" == 1 ]; then
    echo "$(realpath ".")"
  elif [ "$1" == 2 ]; then
    echo "$(realpath "$2")"
  elif [ "$1" == 3 ] || [ "$1" == 4 ]; then
    echo "$(realpath "$(dirname "$(run_manager_cmd \
      'print(get_match("examples", [("name", "'$3'")]))')")")"
  fi
}

function submission_dockerfile() {
  # $1 mode (numeric), $2 mode_details, $3 example name,
  if [ "$1" == 1 ]; then
    echo "$(echo "$2" | sed 's/\/\?\s*$//')$([ ! -f "$2" ] && \
      echo "/Dockerfile")"
  elif [ "$1" == 4 ]; then
    contfn="$(run_manager_cmd 'x = get_value_by_name("examples", "'$3'", \
      "container_filename"); x and print(x)')"
    contdir="$(run_manager_cmd 'x = get_value_by_name("examples", "'$3'", \
      "container_directory"); x and print(x)')"
    echo "$([ -z "$contfn"] && echo "$contdir/Dockerfile" || echo "$contfn" )"
  fi
}

function submission_mode() {
  # Returns a numeric submission mode given the arguments. Valid submission
  # modes are:
  # 0 - submission via native command
  # 1 - containerised submission via Docker
  # 2 - submission via tarring for uploading elsewhere
  # 3 - example submission via native command
  # 4 - example containerised submission via Docker
  # $1 example name, $2 example_containerised, $3 mode
  mode="$(expand_mode $3)"
  if [ -n "$1" ] && [ -z "$2" ]; then
    echo 3
  elif [ -n "$1" ]; then
    echo 4
  elif [ "$mode" == "submission" ]; then
    echo 2
  elif [ "$mode" == "containerised" ]; then
    echo 1
  elif [ "$mode" == "native" ]; then
    echo 0
  fi
}

function submission_mode_string() {
  # $1 mode (numeric), $2 example
  if [ "$1" == 0 ]; then
    echo "Native"
  elif [ "$1" == 1 ]; then
    echo "Containerised"
  elif [ "$1" == 2 ]; then
    echo "Submission *.tgz creation"
  elif [ "$1" == 3 ]; then
    echo "Native (with example '$2')"
  elif [ "$1" == 4 ]; then
    echo "Containerised (with example '$2')"
  fi
}

function submission_output() {
  # $1 mode (numeric), $2 args
  if [ "$1" == 2 ]; then
    [ -z "${2:-}" ] && echo "$SUBMISSION_OUTPUT_DEFAULT" || echo "$2"
  fi
}

################################################################################
#################### Parse & handle command line arguments #####################
################################################################################

# Safely parse options input
_args="args:,evaluate-with:,example:,example-containerised,help,containerised:,\
list-examples,native:,results-location:,show-example:,submission:,version"
parse_out=$(getopt -o a:e:E:hc:n:r:s:v --long $_args -n "$(basename "$0")" \
  -- "$@")
if [ $? != 0 ]; then exit 1; fi
eval set -- "$parse_out"
args=
evaluate_method=
example=
example_containerised=
extra_args=
mode=
mode_details=
mode_dup=
results_location=
while true; do
  case "$1" in
    -a|--args)
      args="$2" ; shift 2 ;;
    -e|--evaluate-with)
      evaluate_method="$2" ; shift 2 ;;
    -E|--example)
      example="$2"; shift 2 ;;
    --example-containerised)
      example_containerised=1; shift 1 ;;
    -h|--help)
      echo "$usage_text" ; shift ; exit 0 ;;
    --list-examples)
      list_content "examples" "$_list_examples_pre" "an"; exit $? ;;
    -n|--native|-c|--containerised|-s|--submission)
      if [ -n "$mode" ]; then mode_dup=1; fi
      mode="$1"; mode_details="$2" ; shift 2 ;;
    -r|--results-location)
      results_location="$2"; shift 2 ;;
    --show-example)
      show_content "examples" "$2"; exit $? ;;
    -v|--version)
      print_version_info; exit ;;
    --)
      extra_args=$(echo "$@" | sed 's/-- *//'); break ;;
    *)
      echo "$(basename "$0"): option '$1' is unknown"; shift ; exit 1 ;;
  esac
done

# Generate any derived configuration parameters
mode=$(expand_mode "$mode")
mode_num="$(submission_mode "$example" "$example_containerised" "$mode")"
mode_details="$(echo "$mode_details $extra_args" | sed 's/^\s*//; s/\s*$//')"

# Bail if any of the requested configurations are invalid
validate_submit_args "$evaluate_method" "$example" "$example_containerised" \
  "$mode" "$mode_num" "$mode_dup" "$mode_details" "$results_location" "$args"

################################################################################
################## Submit your BenchBot solution as requested ##################
################################################################################

# Before we start a submission, figure out all of our derived configuration
sub_str="$(submission_mode_string $mode_num $example)"
sub_str_short="$(echo "$sub_str" | sed 's/ *(.*$//')"
sub_cmd="$(submission_command "$mode_num" "$mode_details" "$example" "$args")"
sub_dir="$(submission_directory "$mode_num" "$mode_details" "$example")"
sub_df="$(submission_dockerfile "$mode_num" "$mode_details" "$example")"
sub_out="$(submission_output "$mode_num" "$args")"

# Now print relevant configuration information
mode_string=""
echo "Submitting to the BenchBot system with the following settings:

    Submission mode:             $sub_str"
echo \
"    Perform evaluation:          "\
"$([ -z "$evaluate_method" ] && echo "No" || echo "Yes ($evaluate_method)")"
if [ -n "$results_location" ]; then
  echo \
"    Results save location:       $results_location"
fi
echo ""
echo \
"    Command to execute:          $sub_cmd"
echo \
"    Command directory:           $sub_dir"
if [ -n "$sub_df" ]; then
  echo \
"    Dockerfile to build:         $sub_df"
fi
if [ -n "$sub_df" ] && [ -n "$args" ]; then
  echo \
"    Docker runtime args:         $args"
fi
if [ -n "$sub_out" ]; then
  echo \
"    Output *.tgz filename:       $sub_out"
fi
echo ""

# Actually perform the submission
header_block "Running submission in '$sub_str_short' mode" ${colour_green}

trap "exit_gracefully $mode_num"  SIGINT SIGQUIT SIGKILL SIGTERM EXIT

# Clear out any previous results in default location
results_src=
if [ -n "$results_location" ] || [ -n "$evaluate_method" ]; then
  results_src=$(python3 -c \
    'from benchbot_api.benchbot import RESULT_LOCATION; print(RESULT_LOCATION)')
  rm -rf "$results_src"
  printf "\nRemoved any existing cached results from: $results_src\n\n"
fi

# Handle the submission
if [ "$mode_num" == 0 ] || [ "$mode_num" == 3 ]; then
  # This is native submission mode
  printf "%s\n\n\t%s\n\n%s\n\n\t%s\n\n" \
    "Running submission natively via command:" "'$sub_cmd'" "In directory:" \
    "'$sub_dir'"
  pushd "$sub_dir" >/dev/null
  set +e
  eval "$sub_cmd"
  run_ret=$?
  set -e
  popd >/dev/null
elif [ "$mode_num" == 2 ]; then
  # This is bundling up submission mode
  echo -e "Bundling up submission from '$sub_dir' to '$sub_out' ...\n"
  pushd "$sub_dir" >/dev/null
  set +e
  eval  "$sub_cmd"
  run_ret=$?
  set -e
  popd >/dev/null
  if [ $run_ret -eq 0 ]; then echo -e "\nSaved to: $sub_out"; fi
elif [ "$mode_num" == 1 ] || [ "$mode_num" == 4 ]; then
  # This is a containerised submission
  echo "Containerising '$sub_df' ..."
  pushd "$sub_dir" >/dev/null
  submission_tag="benchbot/submission:"$(echo "$(pwd)" | sha256sum | cut -c1-10)
  eval "$(echo "$sub_cmd" | sed \
    "s/docker build /\0 -t '${submission_tag//\//\\\/}' /")" &
  active_pid=$!
  wait $active_pid && run_ret=0 || run_ret=1
  if [ $run_ret -ne 0 ]; then
    echo "Docker build returned a non-zero error code: $run_ret"
  else
    xhost +local:root
    echo "Waiting for Docker network ('$DOCKER_NETWORK') to become available..."
    while [ -z "$(docker network ls -q -f 'name='$DOCKER_NETWORK)" ]; do
      sleep 1;
    done
    set +e
    # TODO PASSTHROUGH THE ARGS!!!
    docker run --gpus all -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
      --network "$DOCKER_NETWORK" --name="$SUBMISSION_CONTAINER_NAME" \
      --hostname="$SUBMISSION_CONTAINER_NAME" \
      -e args="$args" -it "$submission_tag"
    run_ret=$?
    set -e
    xhost -local:root
  fi
  popd >/dev/null
else
  echo "Run in unsupported mode '$mode_num' (this error should never happen!)"
  run_ret=1
fi

# Exit here if the submission failed
if [ $run_ret -ne 0 ]; then
  printf "${colour_red}\n%s: %d${colour_nc}\n" \
    "Submission failed with result error code" "$run_ret"
  exit_code=$run_ret
  exit
fi

# Perform any evaluation that may have been requested by the caller
if [ -n "$results_location" ] || [ -n "$evaluate_method" ]; then
  header_block "Processing results" ${colour_blue}

  # Pull the results out of the container if appropriate
  if [ "$mode_num" == 1 ] || [ "$mode_num" == 4 ]; then
    if ! docker cp "${SUBMISSION_CONTAINER_NAME}:${results_src}"\
      "${results_src}" 2>/dev/null; then
      printf "${colour_yellow}\n%s%s${colour_nc}\n" \
        "Failed to extract results from submission container; were there any?"
      echo "{}" > "${results_src}"
    fi
    printf "\nExtracted results from container '%s', to '%s'.\n" \
      "$SUBMISSION_CONTAINER_NAME" "$results_src"
  fi

  # Warn & write some empty results if there are none available
  if [ ! -f "$results_src" ]; then
    printf "\n${colour_yellow}%s\n  ${results_src}${colour_nc}\n" \
      "Requested use of results, but the submission saved no results to: "
    echo "{}" > "${results_src}"
  fi

  # Copy results to a new location if requested
  if [ -n "$results_location" ]; then
    printf "\nCopying results from '%s' to '%s' ...\n" "$results_src" \
      "$results_location"
    rsync -avP "$results_src" "$results_location"
  fi

  # Run evaluation on the results if requested
  if [ -n "$evaluate_method" ]; then
    if [ -z "$results_location" ]; then results_location="$results_src"; fi
    printf "\nRunning evaluation on results from '%s' ... \n" \
      "$results_location"
    benchbot_eval --method "$evaluate_method" "$results_location"
  fi
fi

exit
